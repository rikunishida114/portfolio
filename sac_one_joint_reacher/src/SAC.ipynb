{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import deque\n",
    "import random\n",
    "import gym\n",
    "\n",
    "# シミュレーション条件\n",
    "EPISODES_MAX = 3000000 # エピソード\n",
    "STEPS_MAX = 30\n",
    "DT = 0.01  # 時間ステップ\n",
    "THRESHOLD = 0.05\n",
    "THRESHOLD_REWARD = - 0.9\n",
    "GOAL_POS = [0.0, 1.0]\n",
    "THETA_INIT = 60 # [deg]\n",
    "STEPS_INIT = 0\n",
    "WARMUP_EPISODE = 15000\n",
    "EVALUATION_EPISODE = 100\n",
    "EVAL_INTERVAL = 1000\n",
    "\n",
    "SUCCESS_THRESHOLD_HIGH = 0.8\n",
    "SUCCESS_THRESHOLD_LOW = 0.5\n",
    "\n",
    "\n",
    "# 制御対象\n",
    "L = 1.0  # アームの長さ\n",
    "THETA_MAX = 180\n",
    "THETA_MIN = 0\n",
    "\n",
    "# 強化学習のパラメータ\n",
    "ACTION_MIN = - 200 # [deg/s]\n",
    "ACTION_MAX = 200 # [deg/s]\n",
    "STATE_THETA_MAX = np.pi\n",
    "STATE_THETA_MIN = 0.0\n",
    "REWARD_G = 30\n",
    "REWARD_D = 300\n",
    "REWARD_P_JE = 0.00000000001\n",
    "REWARD_JE_LIM = 0.000001\n",
    "REWARD_P_V = 5.0\n",
    "REWARD_P_T = 0.3\n",
    "REWARD_STD_V = 1.0\n",
    "REWARD_STD_T = 0.1\n",
    "REWARD_STD_J = 10\n",
    "TIME_PUNISH = 0.3\n",
    "ALPHA = 0.5\n",
    "BUFFER_SIZE = 1000000 #30000 episodes分\n",
    "WARMUP_SIZE = 200000\n",
    "TRAIN_INTARVAL = 10\n",
    "BATCH_SIZE = 128\n",
    "SIGMA = 0.9\n",
    "SOFT_TARGET_TAU = 0.02\n",
    "HARD_TARGET_INTERVAL = 100\n",
    "LOG_2PI = tf.constant(np.log(2.0 * np.pi), dtype=tf.float32)\n",
    "\n",
    "\n",
    "# ニューラルネットワークのパラメータ\n",
    "GAMMA = 0.99\n",
    "GAMMA_P = 0.003\n",
    "GAMMA_V = 0.01\n",
    "RAYER_INPUT = 3\n",
    "RAYER_OUTPUT_V = 1\n",
    "RAYER_OUTPUT_M = 1\n",
    "RAYER_OUTPUT_S = 1\n",
    "RAYER_HIDDEN =32\n",
    "\n",
    "# データ保存\n",
    "SAVE_INTERVAL = 10000  # 1000エピソードごとに詳細データを保存\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ログを詳細に出力\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# GPUを使った行列演算\n",
    "a = tf.constant([[1.0]])\n",
    "b = tf.constant([[2.0]])\n",
    "c = a @ b\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneJointReachingEnv(gym.Env):\n",
    "    \"\"\"1関節アームのリーチング運動環境\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # シミュレーションパラメータ（外部定義が必要）\n",
    "        self.dt = DT                          # 時間刻み幅\n",
    "        self.l = L                            # アームの長さ\n",
    "        self.max_steps = STEPS_MAX            # 最大ステップ数\n",
    "        self.goal_threshold = THRESHOLD       # ゴール判定閾値\n",
    "        self.reward_j = 0          # 躍度ペナルティ重み\n",
    "\n",
    "        # 状態空間：[角度, 角速度, 経過時間]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([STATE_THETA_MIN, ACTION_MIN, 0]),\n",
    "            high=np.array([STATE_THETA_MAX, ACTION_MAX, 1]),\n",
    "            shape=(3,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # アクション空間：角速度（ラジアン）\n",
    "        self.action_space = gym.spaces.Box(\n",
    "            low=np.radians(ACTION_MIN),\n",
    "            high=np.radians(ACTION_MAX),\n",
    "            shape=(1,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # 目標座標\n",
    "        self.goal_pos = np.array(GOAL_POS)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def set_penalty_weight(self, new_weight):\n",
    "        \"\"\"躍度ペナルティの重みを外部から設定\"\"\"\n",
    "        self.reward_j = new_weight\n",
    "\n",
    "    def reached_goal(self, dist_to_goal):\n",
    "        \"\"\"目標まで到達したかを判定\"\"\"\n",
    "        return dist_to_goal <= self.goal_threshold\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"現在の観測状態を返す\"\"\"\n",
    "        return np.array([self.theta, self.theta_vel, self.steps / self.max_steps], dtype=np.float32)\n",
    "\n",
    "    def calicuram(self, episode):\n",
    "        \"\"\"カスタム報酬調整用関数（用途に応じて利用）\"\"\"\n",
    "        return (episode / EPISODES_MAX) * 20\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"環境のリセット\"\"\"\n",
    "        self.theta = np.radians(THETA_INIT)\n",
    "        self.steps = STEPS_INIT\n",
    "\n",
    "        self.theta_vel = 0.0\n",
    "        self.theta_acc = 0.0\n",
    "        self.theta_jerk = 0.0\n",
    "\n",
    "        self.jerk_sum = 0.0\n",
    "        self.jerk_mem = 0.0\n",
    "        self.reward_dist = 0.0\n",
    "\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"1ステップの実行\"\"\"\n",
    "\n",
    "        # 直前の状態を記録\n",
    "        prev_theta = self.theta\n",
    "        prev_vel = self.theta_vel\n",
    "        prev_acc = self.theta_acc\n",
    "\n",
    "        # 角度の更新（クリッピングあり）\n",
    "        self.theta += np.clip(action[0], ACTION_MIN, ACTION_MAX) * self.dt\n",
    "        self.theta = np.clip(self.theta, THETA_MIN, np.radians(THETA_MAX))\n",
    "\n",
    "        # 動力学の更新（速度・加速度・躍度）\n",
    "        self.update_dynamics(prev_theta, prev_vel, prev_acc)\n",
    "\n",
    "        # 躍度の累積\n",
    "        self.jerk_sum += self.dt * self.theta_jerk ** 2\n",
    "        self.steps += 1\n",
    "\n",
    "        # 手先位置と目標までの距離\n",
    "        hand_pos = self.l * np.array([np.cos(self.theta), np.sin(self.theta)])\n",
    "        dist_to_goal = np.linalg.norm(hand_pos - self.goal_pos)\n",
    "\n",
    "        # 報酬内訳\n",
    "        if self.steps < self.max_steps:\n",
    "            reward_components = {\n",
    "                \"reward_dist\": 0.0,\n",
    "                \"penalty_jerk\": 0.0,\n",
    "                \"penalty_vel\": 0.0,\n",
    "                \"penalty_time\": 0.0,\n",
    "            }\n",
    "        else:\n",
    "            reward_components = {\n",
    "                \"reward_dist\": -REWARD_D * dist_to_goal**2,\n",
    "                \"penalty_jerk\": - self.reward_j * self.jerk_sum,\n",
    "                \"penalty_vel\": -REWARD_P_V * self.theta_vel**2,\n",
    "                \"penalty_time\": 0.0\n",
    "            }\n",
    "\n",
    "        # 合計報酬\n",
    "        reward = sum(reward_components.values())\n",
    "\n",
    "        # 終了条件\n",
    "        done = self.steps >= self.max_steps\n",
    "\n",
    "        # デバッグ用情報\n",
    "        info = {\n",
    "            \"hand_pos\": hand_pos,\n",
    "            \"theta_vel\": self.theta_vel,\n",
    "            \"theta_acc\": self.theta_acc,\n",
    "            \"theta_jerk\": self.theta_jerk,\n",
    "            \"dist_to_goal\": dist_to_goal,\n",
    "            \"reward_total\": reward,\n",
    "            \"rate_jerk\": 100* self.reward_j/REWARD_JE_LIM,\n",
    "            **reward_components\n",
    "        }\n",
    "\n",
    "        return self._get_obs(), reward, done, info\n",
    "\n",
    "    def update_dynamics(self, prev_theta, prev_vel, prev_acc):\n",
    "        \"\"\"関節の運動量（速度・加速度・躍度）の更新\"\"\"\n",
    "        self.theta_vel = (self.theta - prev_theta) / self.dt\n",
    "        self.theta_acc = (self.theta_vel - prev_vel) / self.dt\n",
    "        self.theta_jerk = (self.theta_acc - prev_acc) / self.dt\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyModel(keras.Model):\n",
    "    \"\"\"Soft Actor-Critic 用の方策モデル（Squashed Gaussian）\"\"\"\n",
    "\n",
    "    def __init__(self, action_space):\n",
    "        super().__init__()\n",
    "        self.action_space = action_space\n",
    "\n",
    "        # アクション空間のスケーリング情報\n",
    "        self.action_center = (action_space.high + action_space.low) / 2.0\n",
    "        self.action_scale = (action_space.high - action_space.low) / 2.0\n",
    "\n",
    "        # ネットワーク構造（入力3次元：角度・速度・時間）\n",
    "        self.hidden1 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\", input_shape=(3,))\n",
    "        self.hidden2 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "        self.hidden3 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "\n",
    "        # 平均と対数標準偏差（出力次元はアクション次元）\n",
    "        self.mean_layer = keras.layers.Dense(action_space.shape[0], activation=\"linear\")\n",
    "        self.log_std_layer = keras.layers.Dense(action_space.shape[0], activation=\"linear\")\n",
    "\n",
    "        # オプティマイザ（学習率は適宜調整）\n",
    "        self.optimizer = Adam(learning_rate=0.003)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"平均と標準偏差を出力（正規分布のパラメータ）\"\"\"\n",
    "        x = self.hidden1(inputs)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "\n",
    "        mean = self.mean_layer(x)\n",
    "        log_std = tf.clip_by_value(self.log_std_layer(x), -20.0, 2.0)  # 安定化のためクリップ\n",
    "        stddev = tf.exp(log_std)\n",
    "\n",
    "        return mean, stddev\n",
    "\n",
    "    @tf.function\n",
    "    def sample_actions(self, states, training=False):\n",
    "        \"\"\"アクションをサンプル（Squashed Gaussian Policy）\"\"\"\n",
    "        mean, stddev = self(states, training)\n",
    "        normal_sample = tf.random.normal(mean.shape)\n",
    "\n",
    "        # 学習時はサンプル、推論時は平均のみ\n",
    "        raw_action = mean + stddev * normal_sample if training else mean\n",
    "        squashed_action = tf.tanh(raw_action)  # [-1, 1] に変換\n",
    "\n",
    "        return squashed_action, mean, stddev, raw_action\n",
    "\n",
    "    def sample_action(self, states, training=False):\n",
    "        \"\"\"環境用にアクションをスケーリングして返す\"\"\"\n",
    "        states = states.reshape(1, -1)\n",
    "        squashed_action, _, _, _ = self.sample_actions(states, training)\n",
    "        squashed_action = squashed_action.numpy()[0]\n",
    "\n",
    "        # 環境用のスケーリング（実アクション空間へ）\n",
    "        env_action = squashed_action * self.action_scale + self.action_center\n",
    "        return env_action, squashed_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualQNetwork(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Q1ネットワーク（入力: 状態3次元 + アクション1次元 = 4次元）\n",
    "        self.dense1 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\", input_shape=(4,))\n",
    "        self.dense2 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "        self.dense3 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "        self.dense4 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "        self.value1 = keras.layers.Dense(RAYER_HIDDEN, activation=\"linear\")\n",
    "\n",
    "        # Q2ネットワーク（同様に）\n",
    "        self.dense5 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\", input_shape=(4,))\n",
    "        self.dense6 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "        self.dense7 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "        self.dense8 = keras.layers.Dense(RAYER_HIDDEN, activation=\"relu\")\n",
    "        self.value2 = keras.layers.Dense(RAYER_OUTPUT_V, activation=\"linear\")\n",
    "\n",
    "        # 最適化手法\n",
    "        self.optimizer = Adam(learning_rate=0.003)\n",
    "\n",
    "    def call(self, states, actions, training=False):\n",
    "        x = tf.concat([states, actions], axis=1)  # shape: (batch, 4)\n",
    "\n",
    "        # Q1分岐\n",
    "        x1 = self.dense1(x)\n",
    "        x1 = self.dense2(x1)\n",
    "        x1 = self.dense3(x1)\n",
    "        x1 = self.dense4(x1)\n",
    "        q1 = self.value1(x1)\n",
    "\n",
    "        # Q2分岐\n",
    "        x2 = self.dense5(x)\n",
    "        x2 = self.dense6(x2)\n",
    "        x2 = self.dense7(x2)\n",
    "        x2 = self.dense8(x2)\n",
    "        q2 = self.value2(x2)\n",
    "\n",
    "        return q1, q2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_logpi(mean, stddev, action):\n",
    "    \"\"\"通常の正規分布における log π(a|s) を計算\"\"\"\n",
    "    log2pi = tf.constant(np.log(2.0 * np.pi), dtype=tf.float32)#定数を定めるときに用いる\n",
    "    log_prob = -0.5 * ((action - mean) / stddev) ** 2 \\\n",
    "               - tf.math.log(stddev) \\\n",
    "               - 0.5 * log2pi #logpiをlogにする\n",
    "    return tf.reduce_sum(log_prob, axis=1, keepdims=True)#actionが多次元で違う確率分布によって出力される場合、logで足し合わせ\n",
    "\n",
    "# Squashed Gaussian Policy時の logπ(a|s)\n",
    "\n",
    "@tf.function\n",
    "def compute_logpi_sgp(mean, stddev, pre_tanh_action):\n",
    "    \"\"\"Squashed Gaussian Policy の log π(a|s) を計算\"\"\"\n",
    "    logpi = compute_logpi(mean, stddev, pre_tanh_action)\n",
    "    # tanhの逆変換でlogπ修正（確率分布が圧縮されているから、それを伸ばす）\n",
    "    log_det_jacobian = tf.reduce_sum(tf.math.log(1 - tf.tanh(pre_tanh_action) ** 2 + 1e-6), axis=1, keepdims=True)\n",
    "    return logpi - log_det_jacobian\n",
    "\n",
    "def update_model(\n",
    "        policy_model, \n",
    "        q_model, \n",
    "        target_q_model,\n",
    "        experiences,\n",
    "        BATCH_SIZE,\n",
    "        SIGMA,\n",
    "        log_alpha,\n",
    "        log_alpha_optimizer,  # 追加\n",
    "        soft_target_tau,\n",
    "        hard_target_interval,\n",
    "        target_entropy,\n",
    "        all_train_count,\n",
    "    ):\n",
    "\n",
    "    \"\"\"SACアルゴリズムの1ステップ更新\"\"\"\n",
    "    alpha = tf.math.exp(log_alpha)#何を計算してる？\n",
    "\n",
    "    # ミニバッチのサンプリング\n",
    "    batchs = random.sample(experiences, BATCH_SIZE)\n",
    "    states = np.asarray([e[\"state\"] for e in batchs])\n",
    "    n_states = np.asarray([e[\"n_state\"] for e in batchs])\n",
    "    actions = np.asarray([e[\"action\"] for e in batchs])\n",
    "    rewards = np.asarray([e[\"reward\"] for e in batchs]).reshape((-1, 1))\n",
    "    dones = np.asarray([e[\"done\"] for e in batchs]).reshape((-1, 1))\n",
    "\n",
    "    # --- 次状態からアクションとlogπの計算\n",
    "    n_actions, n_means, n_stddevs, n_action_orgs = policy_model.sample_actions(n_states)\n",
    "    n_logpi = compute_logpi_sgp(n_means, n_stddevs, n_action_orgs)\n",
    "\n",
    "    # --- 目標Q値の計算\n",
    "    n_q1, n_q2 = target_q_model(n_states, n_actions)\n",
    "    q_vals = rewards + (1 - dones) * GAMMA * tf.minimum(n_q1, n_q2) - (alpha * n_logpi)#logpi(at+1|st+1)になるらしい\n",
    "\n",
    "    # --- Qモデルの学習\n",
    "    with tf.GradientTape() as tape:\n",
    "        q1, q2 = q_model(states, actions, training=True)\n",
    "        loss1 = tf.reduce_mean(tf.square(q_vals - q1))#2乗してバッチごとに平均\n",
    "        loss2 = tf.reduce_mean(tf.square(q_vals - q2))\n",
    "        q_loss = loss1 + loss2#何で和を取るの？\n",
    "\n",
    "    grads = tape.gradient(q_loss, q_model.trainable_variables)\n",
    "    q_model.optimizer.apply_gradients(zip(grads, q_model.trainable_variables))\n",
    "\n",
    "    # --- ポリシーの学習\n",
    "    with tf.GradientTape() as tape:\n",
    "        selected_actions, means, stddevs, action_orgs = policy_model.sample_actions(states, training=True)\n",
    "        logpi = compute_logpi_sgp(means, stddevs, action_orgs)\n",
    "        q1, q2 = q_model(states, selected_actions)\n",
    "        q_min = tf.minimum(q1, q2)\n",
    "        policy_loss = -tf.reduce_mean(q_min - tf.stop_gradient(alpha) * logpi)#バッチ学習を行なっているため個々の損失ではなく、バッチ全体の平均損失について計算\n",
    "\n",
    "    grads = tape.gradient(policy_loss, policy_model.trainable_variables)#lossの計算に関与したモデルの学習可能変数に対する勾配を求める. policy_model.trainable_variablesはモデル内部の 重みやバイアスなどの学習対象の変数\n",
    "    policy_model.optimizer.apply_gradients(zip(grads, policy_model.trainable_variables))\n",
    "\n",
    "    # --- log_alphaの更新\n",
    "    with tf.GradientTape() as tape:\n",
    "        entropy_diff = -logpi - target_entropy\n",
    "        log_alpha_loss = tf.reduce_mean(tf.exp(log_alpha) * entropy_diff)\n",
    "\n",
    "    grad = tape.gradient(log_alpha_loss, [log_alpha])\n",
    "    log_alpha_optimizer.apply_gradients(zip(grad, [log_alpha]))\n",
    "\n",
    "    # --- ソフトターゲット更新\n",
    "    target_q_model.set_weights([\n",
    "        (1 - soft_target_tau) * w + soft_target_tau * t \n",
    "        for w, t in zip(target_q_model.get_weights(), q_model.get_weights())\n",
    "    ])\n",
    "\n",
    "    # --- ハードターゲット同期（一定ステップごと）\n",
    "    if all_train_count % hard_target_interval == 0:\n",
    "        target_q_model.set_weights(q_model.get_weights())\n",
    "\n",
    "    return policy_loss, q_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main():\n",
    "    # 保存用ディレクトリの作成\n",
    "    result_dir = \"results_5_14\"\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    max_episodes = EPISODES_MAX\n",
    "\n",
    "    # 早期終了条件の確認\n",
    "    def check_early_stop(history, episode):\n",
    "        if episode < 1000:\n",
    "            return False\n",
    "        recent = [r[\"total\"] for r in history[-100:]]\n",
    "        avg_reward = np.mean(recent)\n",
    "        print(f\"EarlyStop Check @Ep{episode}: AvgReward={avg_reward:.4f}\")\n",
    "        return avg_reward > THRESHOLD_REWARD\n",
    "\n",
    "    # 初期化\n",
    "    env = OneJointReachingEnv()\n",
    "    env.set_penalty_weight(0)\n",
    "    penalty_weight = 0\n",
    "\n",
    "    target_entropy = -1 * env.observation_space.shape[0]\n",
    "    policy_model = PolicyModel(env.action_space)\n",
    "    q_model, target_q_model = DualQNetwork(), DualQNetwork()\n",
    "\n",
    "    # モデル初期化\n",
    "    dummy_state = np.random.normal(0, 0.1, size=(1,) + env.observation_space.shape)\n",
    "    dummy_action = np.random.normal(0, 0.1, size=(1,) + env.action_space.shape)\n",
    "    q_model(dummy_state, dummy_action)\n",
    "    target_q_model(dummy_state, dummy_action)\n",
    "    target_q_model.set_weights(q_model.get_weights())\n",
    "\n",
    "    log_alpha = tf.Variable(0.0, dtype=tf.float32)\n",
    "    alpha_optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "    # 経験バッファと履歴\n",
    "    replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "    history_rewards, history_metrics, history_metrics_y, episode_results = [], [], [], []\n",
    "\n",
    "    total_steps, train_count = 0, 0\n",
    "    is_last_episode = False\n",
    "\n",
    "    for episode in range(max_episodes):\n",
    "        state = np.asarray(env.reset())\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        rate_jerk = 0\n",
    "        step = 0\n",
    "        metrics_list = []\n",
    "        success = False\n",
    "\n",
    "        is_last_episode = (episode == max_episodes - 1)\n",
    "\n",
    "        # 初期状態記録\n",
    "        step_data = [f\"0 0.00 {L * np.cos(state[0]):.4f} {L * np.sin(state[0]):.4f} {np.degrees(state[0]):.4f} 0.0 0.0 0.0\"]\n",
    "        if is_last_episode:\n",
    "            step_data_eval = [step_data[0]]\n",
    "\n",
    "        while not done:\n",
    "            # 方策に従って行動を選択\n",
    "            action, pre_tanh = policy_model.sample_action(state, training=not is_last_episode)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.asarray(next_state)\n",
    "\n",
    "            # ログ出力\n",
    "            step += 1\n",
    "            total_reward += reward\n",
    "            log_line = (f\"{step} {step * DT:.2f} {info['hand_pos'][0]:.4f} {info['hand_pos'][1]:.4f} \"\n",
    "                        f\"{np.degrees(next_state[0]):.4f} {np.degrees(info['theta_vel']):.4f} \"\n",
    "                        f\"{np.degrees(info['theta_acc']):.4f} {np.degrees(info['theta_jerk']):.4f}\")\n",
    "            step_data.append(log_line)\n",
    "            if is_last_episode:\n",
    "                step_data_eval.append(log_line)\n",
    "\n",
    "            # 学習用データ蓄積と更新\n",
    "            if not is_last_episode:\n",
    "                replay_buffer.append({\n",
    "                    \"state\": state,\n",
    "                    \"action\": pre_tanh,\n",
    "                    \"reward\": reward,\n",
    "                    \"n_state\": next_state,\n",
    "                    \"done\": done,\n",
    "                })\n",
    "                if len(replay_buffer) >= WARMUP_SIZE and total_steps % TRAIN_INTARVAL == 0:\n",
    "                    metrics = update_model(\n",
    "                        policy_model, q_model, target_q_model,\n",
    "                        replay_buffer, BATCH_SIZE, SIGMA,\n",
    "                        log_alpha, alpha_optimizer,\n",
    "                        soft_target_tau=0.02, hard_target_interval=100,\n",
    "                        target_entropy=target_entropy,\n",
    "                        all_train_count=train_count\n",
    "                    )\n",
    "                    train_count += 1\n",
    "                    metrics_list.append(metrics)\n",
    "\n",
    "            state = next_state\n",
    "            total_steps += 1\n",
    "\n",
    "        # ゴール達成判定\n",
    "        if env.reached_goal(info[\"dist_to_goal\"]):\n",
    "            success = True\n",
    "        episode_results.append(success)\n",
    "\n",
    "        # 報酬履歴の保存\n",
    "        history_rewards.append({\n",
    "            \"total\": total_reward,\n",
    "            \"reward_dist\": info.get(\"reward_dist\", 0.0),\n",
    "            \"penalty_jerk\": info.get(\"penalty_jerk\", 0.0),\n",
    "            \"penalty_vel\": info.get(\"penalty_vel\", 0.0),\n",
    "            \"penalty_time\": info.get(\"penalty_time\", 0.0),\n",
    "            \"rate_jerk\": info.get(\"rate_jerk\", 0.0)\n",
    "        })\n",
    "        if metrics_list:\n",
    "            history_metrics.append(np.mean(metrics_list, axis=0))\n",
    "            history_metrics_y.append(episode)\n",
    "\n",
    "        # 成功率に基づいたペナルティ調整\n",
    "        if episode == WARMUP_EPISODE:\n",
    "            penalty_weight = REWARD_P_JE\n",
    "            env.set_penalty_weight(penalty_weight)\n",
    "        \n",
    "        if episode >= WARMUP_EPISODE and (episode + 1) % EVAL_INTERVAL == 0:\n",
    "            success_rate = sum(episode_results[-EVALUATION_EPISODE:]) / EVALUATION_EPISODE\n",
    "            print(f\"[Episode {episode+1}] Success Rate: {success_rate:.2%}\")\n",
    "            if success_rate >= SUCCESS_THRESHOLD_HIGH:\n",
    "                if penalty_weight <= REWARD_JE_LIM:\n",
    "                    penalty_weight *= 1.2\n",
    "                    print(f\"-> 躍度ペナルティ重みを増加\")\n",
    "                else:\n",
    "                    print(\"upper-limit\")\n",
    "            elif success_rate <= SUCCESS_THRESHOLD_LOW:\n",
    "                penalty_weight *= 0.8\n",
    "                print(f\"-> 躍度ペナルティ重みを減少\")\n",
    "            env.set_penalty_weight(penalty_weight)\n",
    "\n",
    "        # ログファイル保存\n",
    "        if (episode + 1) % SAVE_INTERVAL == 0:\n",
    "            with open(f\"{result_dir}/{timestamp}_data_{episode+1}.csv\", \"w\") as f:\n",
    "                f.write(\"Step Time HandX HandY Theta Theta_vel Theta_ac Theta_je\\n\")\n",
    "                f.write(\"\\n\".join(step_data))\n",
    "\n",
    "        if is_last_episode:\n",
    "            with open(f\"{result_dir}/{timestamp}_eval_last_episode.csv\", \"w\") as f:\n",
    "                f.write(\"Step Time HandX HandY Theta Theta_vel Theta_ac Theta_je\\n\")\n",
    "                f.write(\"\\n\".join(step_data_eval))\n",
    "            break\n",
    "            \n",
    "        rate_jerk = info['rate_jerk']\n",
    "        if episode % 100 == 0:\n",
    "            print(f\"Episode: {episode+1} Total Reward: {total_reward:.2f} action: {action} rate_jerk: {rate_jerk:.4f}\" )\n",
    "\n",
    "        #早期終了条件チェック\n",
    "        if (episode + 1) % 100 == 0 and penalty_weight >= REWARD_JE_LIM:\n",
    "            if check_early_stop(history_rewards, episode + 1):\n",
    "                print(f\"✅ 準最適方策を獲得: Ep{episode+1}で学習終了\")\n",
    "                max_episodes = episode + 2\n",
    "                \n",
    "\n",
    "    # 報酬履歴の保存\n",
    "    with open(f\"{result_dir}/{timestamp}_data_sum.csv\", \"w\") as f:\n",
    "        f.write(\"Episode TotalReward RewardDist PenaltyJerk PenaltyVel PenaltyTime\\n\")\n",
    "        for i, r in enumerate(history_rewards):\n",
    "            f.write(f\"{i+1} {r['total']:.4f} {r['reward_dist']:.4f} \"\n",
    "                    f\"{r['penalty_jerk']:.4f} {r['penalty_vel']:.4f} {r['penalty_time']:.4f} {r['rate_jerk']:.4f}\\n\")\n",
    "\n",
    "    print(\"データの保存が完了しました！\")\n",
    "    return policy_model, history_rewards, history_metrics, history_metrics_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total Reward: -69.04 action: [3.2874234] rate_jerk: 0.0000\n",
      "Episode: 101 Total Reward: -76.45 action: [-2.6000917] rate_jerk: 0.0000\n",
      "Episode: 201 Total Reward: -153.59 action: [-1.8304443] rate_jerk: 0.0000\n",
      "Episode: 301 Total Reward: -77.34 action: [-0.34210885] rate_jerk: 0.0000\n",
      "Episode: 401 Total Reward: -73.11 action: [0.42881578] rate_jerk: 0.0000\n",
      "Episode: 501 Total Reward: -67.60 action: [-2.9776487] rate_jerk: 0.0000\n",
      "Episode: 601 Total Reward: -76.54 action: [2.8724666] rate_jerk: 0.0000\n",
      "Episode: 701 Total Reward: -97.50 action: [2.7182648] rate_jerk: 0.0000\n",
      "Episode: 801 Total Reward: -104.10 action: [-2.0294595] rate_jerk: 0.0000\n",
      "Episode: 901 Total Reward: -138.48 action: [-2.9065971] rate_jerk: 0.0000\n",
      "Episode: 1001 Total Reward: -121.59 action: [-2.7873173] rate_jerk: 0.0000\n",
      "Episode: 1101 Total Reward: -112.02 action: [-0.96025467] rate_jerk: 0.0000\n",
      "Episode: 1201 Total Reward: -80.87 action: [1.4598175] rate_jerk: 0.0000\n",
      "Episode: 1301 Total Reward: -90.91 action: [-2.9213495] rate_jerk: 0.0000\n",
      "Episode: 1401 Total Reward: -88.56 action: [-0.86874604] rate_jerk: 0.0000\n",
      "Episode: 1501 Total Reward: -96.04 action: [-2.4071422] rate_jerk: 0.0000\n",
      "Episode: 1601 Total Reward: -40.29 action: [-1.1395214] rate_jerk: 0.0000\n",
      "Episode: 1701 Total Reward: -109.44 action: [1.0994328] rate_jerk: 0.0000\n",
      "Episode: 1801 Total Reward: -109.67 action: [2.5655584] rate_jerk: 0.0000\n",
      "Episode: 1901 Total Reward: -86.70 action: [3.3429189] rate_jerk: 0.0000\n",
      "Episode: 2001 Total Reward: -83.17 action: [-2.3490727] rate_jerk: 0.0000\n",
      "Episode: 2101 Total Reward: -122.26 action: [-2.31156] rate_jerk: 0.0000\n",
      "Episode: 2201 Total Reward: -128.73 action: [2.8554382] rate_jerk: 0.0000\n",
      "Episode: 2301 Total Reward: -131.78 action: [-3.347904] rate_jerk: 0.0000\n",
      "Episode: 2401 Total Reward: -97.60 action: [-1.5026752] rate_jerk: 0.0000\n",
      "Episode: 2501 Total Reward: -155.97 action: [-2.78479] rate_jerk: 0.0000\n",
      "Episode: 2601 Total Reward: -106.33 action: [-2.6820936] rate_jerk: 0.0000\n",
      "Episode: 2701 Total Reward: -79.80 action: [1.7302701] rate_jerk: 0.0000\n",
      "Episode: 2801 Total Reward: -103.13 action: [-3.2795153] rate_jerk: 0.0000\n",
      "Episode: 2901 Total Reward: -66.23 action: [-2.4823937] rate_jerk: 0.0000\n",
      "Episode: 3001 Total Reward: -68.37 action: [2.1131823] rate_jerk: 0.0000\n",
      "Episode: 3101 Total Reward: -69.42 action: [-1.3163598] rate_jerk: 0.0000\n",
      "Episode: 3201 Total Reward: -82.92 action: [1.328725] rate_jerk: 0.0000\n",
      "Episode: 3301 Total Reward: -109.93 action: [2.2839284] rate_jerk: 0.0000\n",
      "Episode: 3401 Total Reward: -141.14 action: [3.1909487] rate_jerk: 0.0000\n",
      "Episode: 3501 Total Reward: -127.03 action: [-3.0189717] rate_jerk: 0.0000\n",
      "Episode: 3601 Total Reward: -99.66 action: [2.5174558] rate_jerk: 0.0000\n",
      "Episode: 3701 Total Reward: -72.20 action: [1.1624943] rate_jerk: 0.0000\n",
      "Episode: 3801 Total Reward: -172.87 action: [2.4517694] rate_jerk: 0.0000\n",
      "Episode: 3901 Total Reward: -115.11 action: [1.8937603] rate_jerk: 0.0000\n",
      "Episode: 4001 Total Reward: -100.86 action: [-3.3376632] rate_jerk: 0.0000\n",
      "Episode: 4101 Total Reward: -154.26 action: [-2.9301639] rate_jerk: 0.0000\n",
      "Episode: 4201 Total Reward: -177.80 action: [3.3270857] rate_jerk: 0.0000\n",
      "Episode: 4301 Total Reward: -95.38 action: [1.1821827] rate_jerk: 0.0000\n",
      "Episode: 4401 Total Reward: -156.36 action: [1.402971] rate_jerk: 0.0000\n",
      "Episode: 4501 Total Reward: -116.42 action: [-2.4954097] rate_jerk: 0.0000\n",
      "Episode: 4601 Total Reward: -54.07 action: [-1.5279434] rate_jerk: 0.0000\n",
      "Episode: 4701 Total Reward: -34.66 action: [0.6475231] rate_jerk: 0.0000\n",
      "Episode: 4801 Total Reward: -119.33 action: [-0.42884138] rate_jerk: 0.0000\n",
      "Episode: 4901 Total Reward: -71.05 action: [1.4330395] rate_jerk: 0.0000\n",
      "Episode: 5001 Total Reward: -156.94 action: [3.420686] rate_jerk: 0.0000\n",
      "Episode: 5101 Total Reward: -106.30 action: [-2.8069198] rate_jerk: 0.0000\n",
      "Episode: 5201 Total Reward: -81.51 action: [3.4791555] rate_jerk: 0.0000\n",
      "Episode: 5301 Total Reward: -118.71 action: [3.208404] rate_jerk: 0.0000\n",
      "Episode: 5401 Total Reward: -100.11 action: [-2.8104637] rate_jerk: 0.0000\n",
      "Episode: 5501 Total Reward: -59.78 action: [1.9131021] rate_jerk: 0.0000\n",
      "Episode: 5601 Total Reward: -128.18 action: [2.679412] rate_jerk: 0.0000\n",
      "Episode: 5701 Total Reward: -135.86 action: [3.4575436] rate_jerk: 0.0000\n",
      "Episode: 5801 Total Reward: -54.34 action: [0.22531341] rate_jerk: 0.0000\n",
      "Episode: 5901 Total Reward: -135.09 action: [1.9936934] rate_jerk: 0.0000\n",
      "Episode: 6001 Total Reward: -144.63 action: [-2.310109] rate_jerk: 0.0000\n",
      "Episode: 6101 Total Reward: -74.96 action: [-0.29499605] rate_jerk: 0.0000\n",
      "Episode: 6201 Total Reward: -34.37 action: [1.4877028] rate_jerk: 0.0000\n",
      "Episode: 6301 Total Reward: -81.34 action: [-2.6806705] rate_jerk: 0.0000\n",
      "Episode: 6401 Total Reward: -56.00 action: [0.24464451] rate_jerk: 0.0000\n",
      "Episode: 6501 Total Reward: -109.27 action: [3.293006] rate_jerk: 0.0000\n",
      "Episode: 6601 Total Reward: -96.44 action: [2.681458] rate_jerk: 0.0000\n",
      "Episode: 6701 Total Reward: -248.93 action: [-1.4321638] rate_jerk: 0.0000\n",
      "Episode: 6801 Total Reward: -63.21 action: [0.68346256] rate_jerk: 0.0000\n",
      "Episode: 6901 Total Reward: -45.80 action: [1.683222] rate_jerk: 0.0000\n",
      "Episode: 7001 Total Reward: -44.09 action: [0.96319795] rate_jerk: 0.0000\n",
      "Episode: 7101 Total Reward: -66.56 action: [-2.420618] rate_jerk: 0.0000\n",
      "Episode: 7201 Total Reward: -123.26 action: [0.8032747] rate_jerk: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[142]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, history_rewards21, history_metrics, history_metrics_y = \u001b[43mtrain_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[141]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mtrain_main\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     77\u001b[39m replay_buffer.append({\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m: state,\n\u001b[32m     79\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m: pre_tanh,\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdone\u001b[39m\u001b[33m\"\u001b[39m: done,\n\u001b[32m     83\u001b[39m })\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(replay_buffer) >= WARMUP_SIZE \u001b[38;5;129;01mand\u001b[39;00m total_steps % TRAIN_INTARVAL == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     metrics = \u001b[43mupdate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_q_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSIGMA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43msoft_target_tau\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhard_target_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_entropy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_entropy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mall_train_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_count\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     train_count += \u001b[32m1\u001b[39m\n\u001b[32m     94\u001b[39m     metrics_list.append(metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[140]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mupdate_model\u001b[39m\u001b[34m(policy_model, q_model, target_q_model, experiences, BATCH_SIZE, SIGMA, log_alpha, log_alpha_optimizer, soft_target_tau, hard_target_interval, target_entropy, all_train_count)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# --- Qモデルの学習\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     q1, q2 = \u001b[43mq_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     loss1 = tf.reduce_mean(tf.square(q_vals - q1))\u001b[38;5;66;03m#2乗してバッチごとに平均\u001b[39;00m\n\u001b[32m     58\u001b[39m     loss2 = tf.reduce_mean(tf.square(q_vals - q2))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2703-nishida-master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/keras/engine/base_layer.py:1043\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1039\u001b[39m   inputs = \u001b[38;5;28mself\u001b[39m._maybe_cast_inputs(inputs, input_list)\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable.enable_auto_cast_variables(\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28mself\u001b[39m._compute_dtype_object):\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m   outputs = \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._activity_regularizer:\n\u001b[32m   1046\u001b[39m   \u001b[38;5;28mself\u001b[39m._handle_activity_regularization(inputs, outputs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[139]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mDualQNetwork.call\u001b[39m\u001b[34m(self, states, actions, training)\u001b[39m\n\u001b[32m     34\u001b[39m x2 = \u001b[38;5;28mself\u001b[39m.dense6(x2)\n\u001b[32m     35\u001b[39m x2 = \u001b[38;5;28mself\u001b[39m.dense7(x2)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m x2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense8\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m q2 = \u001b[38;5;28mself\u001b[39m.value2(x2)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m q1, q2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2703-nishida-master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/keras/engine/base_layer.py:981\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    974\u001b[39m input_list = nest.flatten(inputs)\n\u001b[32m    976\u001b[39m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[32m    977\u001b[39m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[32m    978\u001b[39m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_in_functional_construction_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    982\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._functional_construction_call(inputs, args, kwargs,\n\u001b[32m    983\u001b[39m                                             input_list)\n\u001b[32m    985\u001b[39m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2703-nishida-master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/keras/engine/base_layer.py:3260\u001b[39m, in \u001b[36m_in_functional_construction_mode\u001b[39m\u001b[34m(layer, inputs, args, kwargs, input_list)\u001b[39m\n\u001b[32m   3255\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the arguments to see if we are constructing a functional model.\"\"\"\u001b[39;00m\n\u001b[32m   3256\u001b[39m \u001b[38;5;66;03m# We are constructing a functional model if any of the inputs\u001b[39;00m\n\u001b[32m   3257\u001b[39m \u001b[38;5;66;03m# are KerasTensors\u001b[39;00m\n\u001b[32m   3258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   3259\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(tensor, keras_tensor.KerasTensor)\n\u001b[32m-> \u001b[39m\u001b[32m3260\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/2703-nishida-master-thesis/.venv/lib/python3.12/site-packages/tensorflow/python/util/nest.py:198\u001b[39m, in \u001b[36mflatten\u001b[39m\u001b[34m(structure, expand_composites)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_sequence_or_composite\u001b[39m(seq):\n\u001b[32m    195\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _is_nested_or_composite(seq)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnest.flatten\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflatten\u001b[39m(structure, expand_composites=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    200\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns a flat list from a given structure.\u001b[39;00m\n\u001b[32m    201\u001b[39m \n\u001b[32m    202\u001b[39m \u001b[33;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    TypeError: The nest is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m    293\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m nest_util.flatten(\n\u001b[32m    294\u001b[39m       nest_util.Modality.CORE, structure, expand_composites\n\u001b[32m    295\u001b[39m   )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model, history_rewards21, history_metrics, history_metrics_y = train_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('episode')\n",
    "ax1.grid()\n",
    "ax1.plot(history_metrics_y, [m[0] for m in history_metrics], color=\"C0\", marker='.', label=\"policy_loss\")\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(history_metrics_y, [m[1] for m in history_metrics], color=\"C1\", marker='.', label=\"q_loss\")\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout()  # レイアウトの設定\n",
    "#plt.savefig('cartp\n",
    "# ole2.png') # 画像の保存\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
